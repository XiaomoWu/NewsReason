{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchmetrics\n",
    "import torch\n",
    "\n",
    "# multiclass with logits\n",
    "# (N, C), N=3, C=3\n",
    "preds = torch.tensor([[0.2, 0.8, 0.0], \n",
    "                      [0.1, 0.2, 0.7],\n",
    "                      [0.1, 0.8, 0.1]], \n",
    "                      dtype=torch.float16)\n",
    "target = torch.tensor([1, 0, 0])\n",
    "\n",
    "\n",
    "torchmetrics.functional.classification.multiclass_accuracy(\n",
    "    preds, target, \n",
    "    num_classes=3,\n",
    "    ignore_index=-1,\n",
    "    average='none',\n",
    "    top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.9.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchmetrics.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preds.shape=torch.Size([2, 3, 2])'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'target.shape=torch.Size([2, 2])'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9179)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9179)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multidimensional, multiclass with logits\n",
    "# 2 samples, 3 classes, each sample is of length 2\n",
    "preds = torch.tensor([[[0.2, 0.7, 0.1], [0.1, 0.5, 0.4]], \n",
    "                      [[0.8, 0.1, 0.1], [0.2, 0.1, 0.7]]],\n",
    "                      dtype=torch.float)\n",
    "preds = rearrange(preds, 'n s c -> n c s')\n",
    "\n",
    "target = torch.tensor([[1, 1], \n",
    "                       [0, 0]], dtype=torch.long)\n",
    "\n",
    "f'{preds.shape=}'\n",
    "f'{target.shape=}'\n",
    "\n",
    "# torchmetrics.functional.classification.multiclass_accuracy(\n",
    "#     preds, target, num_classes=3, \n",
    "#     multidim_average='samplewise', average='micro', \n",
    "#     ignore_index=-100)\n",
    "torch.nn.CrossEntropyLoss(ignore_index=-100, reduction='mean')(preds, target)\n",
    "# torch.nn.CrossEntropyLoss(ignore_index=-100, reduction='mean')(preds, target)\n",
    "\n",
    "preds = F.log_softmax(preds, dim=1)\n",
    "F.nll_loss(preds, target, reduction='mean', ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5981, 0.3711, 0.4375],\n",
       "        [0.6444, 0.3711, 0.4375],\n",
       "        [0.6444, 0.3711, 0.4375]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5981, 0.3711, 0.4375],\n",
       "        [0.6444, 0.3711, 0.4375],\n",
       "        [0.6444, 0.3711, 0.4375]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi-label, multi-class\n",
    "preds = torch.tensor([[0.2, 0.8, 0.6], \n",
    "                      [0.1, 0.8, 0.6],\n",
    "                      [0.1, 0.8, 0.6]])\n",
    "\n",
    "target = torch.tensor([[1., 1, 1],\n",
    "                       [1, 1, 1], \n",
    "                       [1, 1, 1]])\n",
    "\n",
    "torchmetrics.functional.classification.multilabel_accuracy(\n",
    "    preds, target,\n",
    "    threshold=0.5,\n",
    "    num_labels=3,\n",
    "    ignore_index=-100,\n",
    "    average='none')\n",
    "\n",
    "torchmetrics.functional.classification.multilabel_accuracy(\n",
    "    preds, target,\n",
    "    threshold=0.5,\n",
    "    num_labels=3,\n",
    "    ignore_index=-100,\n",
    "    average='micro')\n",
    "\n",
    "# torch.nn.functional.sigmoid(preds)\n",
    "# torch.nn.functional.logsigmoid(preds)\n",
    "torch.nn.functional.binary_cross_entropy_with_logits(preds, target, reduction='none')\n",
    "\n",
    "x = torch.nn.functional.sigmoid(preds)\n",
    "torch.nn.functional.binary_cross_entropy(x, target, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.7981)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.tensor(1-0.5498))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.2014)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "target = torch.ones([10, 64], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "output = torch.full([10, 64], 1.5)  # A prediction (logit)\n",
    "output.shape\n",
    "target.shape\n",
    "pos_weight = torch.ones([64])  # All weights are equal to 1\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "criterion(output, target)  # -log(sigmoid(1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#Spark ML and SQL\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "#Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import DocumentAssembler, Finisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/yu/OneDrive/App/python/python-env/py39-base/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/yu/.ivy2/cache\n",
      "The jars for the packages stored in: /home/yu/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-8fa0966f-38f2-4ad0-896a-847931def654;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;4.1.0 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3 in central\n",
      "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/spark-nlp_2.12/4.1.0/spark-nlp_2.12-4.1.0.jar ...\n",
      "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#spark-nlp_2.12;4.1.0!spark-nlp_2.12.jar (3908ms)\n",
      "downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.2/config-1.4.2.jar ...\n",
      "\t[SUCCESSFUL ] com.typesafe#config;1.4.2!config.jar(bundle) (68ms)\n",
      "downloading https://repo1.maven.org/maven2/org/rocksdb/rocksdbjni/6.29.5/rocksdbjni-6.29.5.jar ...\n",
      "\t[SUCCESSFUL ] org.rocksdb#rocksdbjni;6.29.5!rocksdbjni.jar (3652ms)\n",
      "downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.828/aws-java-sdk-bundle-1.11.828.jar ...\n",
      "\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.11.828!aws-java-sdk-bundle.jar (12091ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/universal-automata/liblevenshtein/3.0.0/liblevenshtein-3.0.0.jar ...\n",
      "\t[SUCCESSFUL ] com.github.universal-automata#liblevenshtein;3.0.0!liblevenshtein.jar (80ms)\n",
      "downloading https://repo1.maven.org/maven2/com/navigamez/greex/1.0/greex-1.0.jar ...\n",
      "\t[SUCCESSFUL ] com.navigamez#greex;1.0!greex.jar (96ms)\n",
      "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/tensorflow-cpu_2.12/0.4.3/tensorflow-cpu_2.12-0.4.3.jar ...\n",
      "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3!tensorflow-cpu_2.12.jar (20233ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/annotations/3.0.1/annotations-3.0.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#annotations;3.0.1!annotations.jar (54ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java-util/3.0.0-beta-3/protobuf-java-util-3.0.0-beta-3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java-util;3.0.0-beta-3!protobuf-java-util.jar(bundle) (59ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.0.0-beta-3/protobuf-java-3.0.0-beta-3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java;3.0.0-beta-3!protobuf-java.jar(bundle) (201ms)\n",
      "downloading https://repo1.maven.org/maven2/it/unimi/dsi/fastutil/7.0.12/fastutil-7.0.12.jar ...\n",
      "\t[SUCCESSFUL ] it.unimi.dsi#fastutil;7.0.12!fastutil.jar (1373ms)\n",
      "downloading https://repo1.maven.org/maven2/org/projectlombok/lombok/1.16.8/lombok-1.16.8.jar ...\n",
      "\t[SUCCESSFUL ] org.projectlombok#lombok;1.16.8!lombok.jar (196ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.21!slf4j-api.jar (52ms)\n",
      "downloading https://repo1.maven.org/maven2/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar ...\n",
      "\t[SUCCESSFUL ] net.jcip#jcip-annotations;1.0!jcip-annotations.jar (69ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.1/jsr305-3.0.1.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.1!jsr305.jar (60ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/gson/gson/2.3/gson-2.3.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.gson#gson;2.3!gson.jar (69ms)\n",
      "downloading https://repo1.maven.org/maven2/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar ...\n",
      "\t[SUCCESSFUL ] dk.brics.automaton#automaton;1.11-8!automaton.jar (80ms)\n",
      ":: resolution report :: resolve 3489ms :: artifacts dl 42351ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;4.1.0 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   17  |   17  |   17  |   0   ||   17  |   17  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-8fa0966f-38f2-4ad0-896a-847931def654\n",
      "\tconfs: [default]\n",
      "\t17 artifacts copied, 0 already retrieved (573878kB/310ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:55:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/26 14:55:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "Spark NLP version:  4.1.0\n",
      "Apache Spark version:  3.3.0\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_datetime download started this may take some time.\n",
      "Approx size to download 9.7 KB\n",
      "[ | ]match_datetime download started this may take some time.\n",
      "Approximate size to download 9.7 KB\n",
      "[ / ]Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pipeline = PretrainedPipeline('match_datetime', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Registering annotator sutime with class edu.stanford.nlp.time.TimeAnnotator\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator sutime\n"
     ]
    }
   ],
   "source": [
    "from sutime import SUTime\n",
    "sutime = SUTime(mark_time_ranges=True,\n",
    "                include_range=True, language='english')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('py39-base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8206f256a530121ae25c24162e68178f9aa446642b91710e737959e4bf72a59d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
