# @package _global_
defaults:
  - override /datamodule: nr-class
  - override /model: nr-class
  - override /callbacks:
    - wandb
    - rich-progress-bar
    - model-checkpoint
  - override /trainer: default
  - override /strategy: deepspeed
  - override /logger: wandb

model_id: test
seed: 41
test_after_train: false

model:
  pretrained_model: roberta-large
  d_model: 1024

datamodule:
  coarse: false
  use_biolu: false
  ignore_index: -100

  bsz: 16
  val_bsz: 1
  num_workers: 2

  # determin train/val/test split
  tx_path: /home/yu/OneDrive/NewsReason/local-dev/data/annotation/batch-4/2-annotated/annotated_agreed_full_batch3_4.feather
  
  # if `train_val_test_split` is List[float], 
  #     then use the value as fraction,
  # elif List[int],
  #     then use the value as N samples
  
  train_val_test_split: [1000, 0, 200]  # [1000, 0, 200]
  use_test_as_val: true
  use_train_as_val: false

  # special tokens
  special_tokens: ['[CLS]', '[SEP]', '[PAD]', 
                   '<s>', '</s>', '<pad>']

optimizer:
  lr: 3e-5

trainer:
  min_epochs: 1
  max_epochs: 15
  check_val_every_n_epoch: 1

callbacks:
  model_checkpoint:
    monitor: val/acc
    mode: max
    save_top_k: 1