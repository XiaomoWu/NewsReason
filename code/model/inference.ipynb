{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readme first\n",
    "\n",
    "**What this notebook does:**\n",
    "- Locate and return the reason texts\n",
    "\n",
    "**What this notebook DOES NOT do:**\n",
    "- Return the \"type\" (e.g., External Shock) of the reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datatable as dt\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from IPython.utils import io\n",
    "from pytorch_lightning.utilities.deepspeed import convert_zero_checkpoint_to_fp32_state_dict\n",
    "from src.datamodules.datamodules import NrSpanDataModule\n",
    "from src.models.models import Model\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load deepspeed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing zero checkpoint '/home/yu/OneDrive/NewsReason/local-dev/checkpoints/epoch=11.ckpt/checkpoint'\n",
      "Detected checkpoint of type zero stage 2, world_size: 2\n",
      "Parsing checkpoint created by deepspeed==0.7.3\n",
      "Reconstructed fp32 state dict with 395 params 355387417 elements\n",
      "Saving fp32 state dict to /home/yu/OneDrive/NewsReason/local-dev/checkpoints/ckpt_saved.pt\n"
     ]
    }
   ],
   "source": [
    "def load_checkpoint(zero_ckpt_dir, ckpt_resave_path):\n",
    "    '''\n",
    "    Args:\n",
    "        zero_ckpt_path (str): path to zero checkpoint (when using deepspeed)\n",
    "        pt_ckpt_path (str): path to pt checkpoint (when using ddp)\n",
    "    '''\n",
    "\n",
    "    convert_zero_checkpoint_to_fp32_state_dict(\n",
    "        zero_ckpt_dir, ckpt_resave_path)\n",
    "\n",
    "    return torch.load(ckpt_resave_path)\n",
    "\n",
    "def init_model(device: str):\n",
    "    # ------------------\n",
    "    # load ckpt\n",
    "    # ------------------\n",
    "    zero_ckpt_dir = '/home/yu/OneDrive/NewsReason/local-dev/checkpoints/epoch=11.ckpt'\n",
    "    ckpt_resave_path = '/home/yu/OneDrive/NewsReason/local-dev/checkpoints/ckpt_saved.pt'\n",
    "\n",
    "    ckpt = load_checkpoint(zero_ckpt_dir, ckpt_resave_path)\n",
    "\n",
    "    # ------------------\n",
    "    # collect hparams\n",
    "    # ------------------\n",
    "    hparams = ckpt['hyper_parameters']\n",
    "    datamodule_cfg = hparams['datamodule_cfg']\n",
    "    model_cfg = hparams['model_cfg']\n",
    "\n",
    "    # ------------------\n",
    "    # init model\n",
    "    # ------------------\n",
    "\n",
    "    state_dict = ckpt['state_dict']\n",
    "\n",
    "    with io.capture_output() as captured:\n",
    "        model = Model(**hparams)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "    return model, datamodule_cfg, model_cfg\n",
    "\n",
    "# init model\n",
    "device = 'cuda:0'\n",
    "\n",
    "model, datamodule_cfg, model_cfg = init_model(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NR-Span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/yu/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /home/yu/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /home/yu/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/tokenizer.json from cache at /home/yu/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/yu/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N unique ids=25\n",
      "label_to_id={'[CLS]': -100, '[SEP]': -100, '[PAD]': -100, '<s>': -100, '</s>': -100, '<pad>': -100, 'O': 0, 'B-Firm Action': 1, 'I-Firm Action': 2, 'B-Contrast/Confusion': 3, 'I-Contrast/Confusion': 4, 'B-Demand & Trading': 5, 'I-Demand & Trading': 6, 'B-Operation Outcome': 7, 'I-Operation Outcome': 8, 'B-External Shock': 9, 'I-External Shock': 10, 'B-Labor': 11, 'I-Labor': 12, 'B-Technical': 13, 'I-Technical': 14, 'B-Others': 15, 'I-Others': 16, 'B-Litigation': 17, 'I-Litigation': 18, 'B-Financing': 19, 'I-Financing': 20, 'B-Third Party': 21, 'I-Third Party': 22, 'B-Fraud & Investigation': 23, 'I-Fraud & Investigation': 24}\n"
     ]
    }
   ],
   "source": [
    "def init_dataloader(pretrained_model, tx_path, coarse, n_unique_labels, ignore_index):\n",
    "\n",
    "    datamodule = NrSpanDataModule(\n",
    "        inference=True,\n",
    "        train_val_test_split=[1, 0, 0],\n",
    "        use_biolu=False,\n",
    "        tx_path=tx_path,\n",
    "        ignore_index=ignore_index,\n",
    "        coarse=coarse,\n",
    "        n_unique_labels=n_unique_labels,\n",
    "        special_tokens=['[CLS]', '[SEP]', '[PAD]', '<s>', '</s>', '<pad>'],\n",
    "        pretrained_model=pretrained_model)\n",
    "\n",
    "    datamodule.setup()\n",
    "\n",
    "    return datamodule\n",
    "\n",
    "# init dataloader\n",
    "pretrained_model = 'roberta-large'\n",
    "tx_path = '/home/yu/OneDrive/NewsReason/local-dev/data/annotation/batch-4/2-annotated/annotated_agreed_full_batch3_4.feather'\n",
    "coarse = True\n",
    "# [BIO]: 25 (coarse), 49 (fine) | [BIOLU]: 49 (coarse), 97 (fine)\n",
    "n_unique_labels = 25\n",
    "ignore_index = -100\n",
    "\n",
    "datamodule = init_dataloader(\n",
    "    pretrained_model, tx_path, coarse, n_unique_labels, ignore_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1200 [00:00<00:47, 25.25it/s]\n"
     ]
    }
   ],
   "source": [
    "def inference(datamodule):\n",
    "    '''\n",
    "    '''\n",
    "    # get dataloader\n",
    "    dataloader = datamodule.test_dataloader()\n",
    "    \n",
    "    # get tokenizer\n",
    "    tokenizer = datamodule.tokenizer\n",
    "\n",
    "    # make predictions!\n",
    "    headlines = []\n",
    "    pred_reasons = []\n",
    "\n",
    "    # get speical token_ids (i.e., the ids of speical tokens like [CLS], or </s>)\n",
    "    special_tokens = tokenizer.special_tokens_map.values()\n",
    "    special_token_ids = [tokenizer.convert_tokens_to_ids(t) for t in special_tokens]\n",
    "\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        if i >= 5:\n",
    "            break\n",
    "\n",
    "        input_ids = batch['input_ids'][0].tolist()  # List[int]\n",
    "        texts = batch['texts']  # List[str]\n",
    "\n",
    "        # collect headlines\n",
    "        headlines.append(texts[0])\n",
    "\n",
    "        # predict\n",
    "        batch = {k: v.to(device) for k, v in batch.items()\n",
    "                 if k not in ['texts', 'headline_classes']}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y = model.predict(batch).argmax(-1)[0].cpu()\n",
    "\n",
    "            # get the index of each reason token\n",
    "            y = y.tolist()\n",
    "\n",
    "            # the index of reason token.\n",
    "            reason_token_ixs = []\n",
    "\n",
    "            # the id (in its tokenizer) of each reason token.\n",
    "            reason_token_ids = []\n",
    "\n",
    "            for i, (input_id, token_pred) in enumerate(zip(input_ids, y)):\n",
    "                if (token_pred not in [0, ignore_index]) and (input_id not in special_token_ids):\n",
    "                    reason_token_ixs.append(i)\n",
    "                    reason_token_ids.append(input_id)\n",
    "\n",
    "        # save predicted reasons\n",
    "        reason = tokenizer.convert_tokens_to_string(\n",
    "            tokenizer.convert_ids_to_tokens(reason_token_ids))\n",
    "        pred_reasons.append(reason)\n",
    "\n",
    "    \n",
    "    # save results to a table\n",
    "    return pd.DataFrame({'headline': headlines, 'pred_reasons': pred_reasons})\n",
    "    \n",
    "# run inference\n",
    "inference_output = inference(datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>pred_reasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thor Shares Fall As Company Sees 'headwinds' F...</td>\n",
       "      <td>Company Sees 'headwinds' From Steel Tariffs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mettler-Toledo International Inc. (MTD) Reache...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reed's shares are trading higher after the com...</td>\n",
       "      <td>the company announced an expanded distributio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sector Update: Tech Stocks Ending Near Session...</td>\n",
       "      <td>Q3 Revenue Beat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Office Depot Shares Spike To Near Session Low ...</td>\n",
       "      <td>1.1M Share Block Trade At $3.06/Share Crosses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  Thor Shares Fall As Company Sees 'headwinds' F...   \n",
       "1  Mettler-Toledo International Inc. (MTD) Reache...   \n",
       "2  Reed's shares are trading higher after the com...   \n",
       "3  Sector Update: Tech Stocks Ending Near Session...   \n",
       "4  Office Depot Shares Spike To Near Session Low ...   \n",
       "\n",
       "                                        pred_reasons  \n",
       "0        Company Sees 'headwinds' From Steel Tariffs  \n",
       "1                                                     \n",
       "2   the company announced an expanded distributio...  \n",
       "3                                    Q3 Revenue Beat  \n",
       "4      1.1M Share Block Trade At $3.06/Share Crosses  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39-base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8206f256a530121ae25c24162e68178f9aa446642b91710e737959e4bf72a59d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
